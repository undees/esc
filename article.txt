Testing Embedded User Interfaces
================================

Search the Internet for ``test desktop user interface'' or ``test web
user interface,'' and you'll find dozens of test frameworks nestled
among the books, articles, and blogs.  But if you look for ``test
embedded user interface'' instead, the toolkit pickings are slim.  Why
is that?

A software library for testing desktop software need only deal with
two or three platforms to cover most people's PCs.  The story is even
better for web testing, which only has to support one platform: HTTP.
By contrast, there are hundreds of different kinds of embedded user
interfaces, ranging from full desktop OSes down to no interface at
all.

No testing toolkit or technique could hope to cover more than a small
fraction of the embedded platforms in popular use.  Instead of leaning
on standards or common frameworks, embedded developers must rely on
their own experience and adaptability.

Over the next few pages, we're going to consider various kinds of
embedded systems, including:

* A full desktop OS embedded in a device.
* A touchscreen OS supporting many desktop-like metaphors.
* A interface consisting only of readouts and physical buttons.
* A simple device whose interface is just a few switches and LEDs.

For each one of these categories, we'll look at how we might test a
hypothetical device belonging to that category.

Embedded Desktop GUI
~~~~~~~~~~~~~~~~~~~~

When you have nearly the full power of a desktop OS at your disposal,
you have the luxury of building your test script atop one of the many
GUI automation libraries for your platform.  Moreover, you can often
run a few ``smoke tests'' of the application on your own PC before
deploying to the target device.

Let's imagine a waveform generator whose interface runs on Windows
XPe, the embedded version of Windows XP:

.An embedded desktop GUI
image::images/desktop.png[scaledwidth="60%"]

Here's our test script, written for the Cucumber test framework.
footnote:[http://cukes.info]

--------------------------------------------------------------------
include::desktop/features/waveform.feature[]
--------------------------------------------------------------------

The heart of the test is the section with the +Given+, +When+, and
+Then+ lines.  When Cucumber sees each of those, it looks for a _step
definition_, a piece of glue code representing that single GUI action.
These can be written in any one of a handful of common programming
languages.  For this first example, we'll start in Ruby.

:bos quote: footnote:[http://bit.ly/cobolfetish]

********************************************************************
[quote, Bryan O'Sullivan, 'blog comment (2009) {bosquote}']
____________________________________________________________________
Oh wow.  I never knew that Rubyists had a Cobol fetish.
____________________________________________________________________
********************************************************************

What will the code in each of those definitions look like?  How is it
going to find the running application and click the various controls?
The simplest choice for this demo app is an open-source GUI automation
library called WiPFlash. footnote:[http://wipflash.googlecode.com]
WiPFlash is designed to test programs written using the Windows
Presentation Framework (WPF).  (If you're driving a Windows Forms or a
Win32 program, you may want to look at a more full-featured library
called Project White. footnote:[http://white.codeplex.com].)

The following Ruby code implements the three steps of our test script
by driving the waveform generator's GUI.  While most of the code in
this article will work on any of Ruby's many implementations, this
excerpt requires IronRuby, a version of Ruby that runs on the .NET
platform.

[source,ruby]
--------------------------------------------------------------------
include::nohardware/features/step_definitions/waveform_steps.rb[]
--------------------------------------------------------------------

With that code in +waveform_steps.rb+, you can run the test by
invoking Cucumber from the command line:

--------------------------------------------------------------------
C:\Project> cucumber
--------------------------------------------------------------------

Once we're satisfied that the app passes this simple use case on the
desktop, how do we test it on the real hardware?  For the sake of this
example, let's assume our target hardware is a poor fit for installing
all of IronRuby onto it.  Instead, we'd like to port the step
definitions to C# and move them onto the device, while keeping
Cucumber and the overall test script on our PC.

Porting the WiPFlash calls to C# is easy.  But how do we associate
each step definition with the +Given+, +When+, or +Then+ step it
represents?  The Cuke4Nuke project provides several source-code
attributes you can add to your C# code for this
purpose. footnote:[http://github.com/richardlawrence/cuke4nuke]

[source,csharp]
--------------------------------------------------------------------
include::desktop/steps/WaveformStepsSnippet.cs[]
--------------------------------------------------------------------

Once you've built this code into a DLL, all you have to do is copy it
and the C#-based +Cuke4Nuke.Server.exe+ to the target hardware, then
launch the server:

--------------------------------------------------------------------
C:\Hardware> Cuke4Nuke.Server.exe -a WaveformSteps.dll
--------------------------------------------------------------------

Back on the PC, you'll remove the old +waveform_steps.rb+ file and
replace it with one called +cucumber.wire+, which contains the IP
address of the device under test:

--------------------------------------------------------------------
host: 10.0.0.100
port: 3901
--------------------------------------------------------------------

Now, you can run Cucumber exactly as before.  This time, it will
connect to the server running on the hardware, and direct the tests
over TCP.


Touch-Screen GUI
~~~~~~~~~~~~~~~~

The previous example assumed a full-powered desktop OS was running on
the device.  What if we wanted our waveform generator interface to
work on more stripped-down hardware running Windows CE?

.A touch-screen GUI
image::images/touchscreen.png[scaledwidth="60%"]

Let's say we're running on a device with a low-power-consumption
processor and very little storage, and we've chosen not to include
.NET in the platform build.  We can still use the idea of a server
listening to TCP requests from the PC and performing various GUI
actions.  We'll just have to move some of the smarts up into the PC.
Instead of sending commands over the wire that say, ``Turn on the Sine
waveform,'' we'll send requests for more basic GUI actions, such as
``Tell me the mouse coordinates for control #1005.''

We can use any protocol we want to represent the commands and
parameters.  Why reinvent the wheel?  Let's use HTTP.  Here are the
original Ruby step definitions, with the WiPFlash calls replaced by
HTTP GET requests.

[source,ruby]
--------------------------------------------------------------------
include::touchscreen/features/step_definitions/waveform_steps.rb[]
--------------------------------------------------------------------

As before, the server will run in a standalone process on the
hardware.  There are dozens of embeddable C-based web servers
available.  Mongoose is particularly easy to build for Windows
CE. footnote:[http://mongoose.googlecode.com] Here's what one of the
request handlers looks like.

[source,c]
--------------------------------------------------------------------
include::touchscreen/server/main_snippet.c[]
--------------------------------------------------------------------


Physical UI
~~~~~~~~~~~

All of the examples so far have leaned on GUI controls built into the
operating system.  What if there's no GUI at all--just text painted on
the screen?

.A physical UI
image::images/physical.png[scaledwidth="60%"]

If there's no mouse and no keyboard, how do we simulate the user
pushing a button?  By adding developer hooks to the software.  In this
hypothetical example, the device supports a remote-control interface
with simple commands like +PUSH:BUTTON <name>+.

Such commands are easy to send from Ruby.  But let's mix things up a
little.  Let's say you already had an existing body of Tcl functions
to drive this user interface over the network:

[source,tcl]
--------------------------------------------------------------------
include::physical/tcl/waveform_defs.tcl[]
--------------------------------------------------------------------

It would be nice to be able to reuse these.  Fortunately, you can.
Cucumber can call into Tcl just fine.  All you need is a little Ruby
glue in between:

[source,ruby]
--------------------------------------------------------------------
include::physical/features/step_definitions/waveform_steps.rb[]
--------------------------------------------------------------------

Before moving on, let's perform one final flourish: cutting Ruby and
Cucumber out of the equation, and running the test script purely in
Tcl.  How is this possible?  It turns out that Cucumber syntax, with
its emphasis on spaces over punctuation, looks a lot like Tcl.  To
Tcl, the phrase +When I set the Waveform Type to "Sine"+ is a
simple call to a function named +When+, with parameters +"I"+,
+"set"+, and so on.

So if we define this seven-argument function, and ignore all but the
final parameter, we have something like this:

[source,tcl]
--------------------------------------------------------------------
include::physical/tcl/fun/steps_snippet.tcl[]
--------------------------------------------------------------------

Once we've done the same thing for the rest of the ``functions'' in
the Cucumber test script, we can run the whole thing in Tcl.


Minimal UI
~~~~~~~~~~

Just how far down can this approach scale?  Pretty far.  We're now
going to take a departure from the world of waveform generators and
build a much simpler device.  Unlike the previous hypothetical
examples, this one will be real-world wearable computing project based
on the Lilypad Arduino microcontroller
board. footnote:[http://www.arduino.cc/en/Main/ArduinoBoardLilyPad]

.A minimal UI
image::images/4034984722.jpg[scaledwidth="60%"]

_Image by Osamu
Iwasaki. footnote:[http://www.flickr.com/photos/osamu_iwasaki/4034984722]
Used under a Creative Commons license._
footnote:[http://creativecommons.org/licenses/by-sa/2.0/deed.en]

--------------------------------------------------------------------
include::minimal/features/mood.feature.snippet[]
--------------------------------------------------------------------

[source,ruby]
--------------------------------------------------------------------
include::minimal/features/step_definitions/mood_steps.rb[]
--------------------------------------------------------------------
